Devan Hawkins
998882641
				Assignment #1
Part 1
1) 
The total number of trainable parameters is the sum of:
input-to-embedding-layer weights,
embedding-to-hidden-layer weigths,
hidden layer biases,
hidden-to-output-layer weights, and
output layer biases
= (250 * 16) + (16 * 128) + 128 + (128 * 250) + 250
= 38, 426
Therefore, there are 38, 426 trainable parameters.

From this data, we can see that the output-to-hidden layer part of the model has the most trainable parameters with 250 * 128 = 32 000 of them.

2)
If we were to store the counts all possible 4-grams explicitily, we would have a table with 3,890,625,000 entries. This number is all of the three-word possibilities in the vocabulary (250 * 250 * 250) times all the words in the vocabulary except for a single word in the given column (250 - 1). This makes it 250^3 * 249 = 3,890,625,000.

Part 2
Model.compute_loss_derivative:
dcdy = output_activations - expanded_target_batch
return dcdy

Model.back_propagate:
hid_to_output_weights_grad = np.dot(loss_derivative.T, activations.hidden_layer) 
output_bias_grad = np.sum(loss_derivative, axis=0)
embed_to_hid_weights_grad = np.dot(hid_deriv.T, activations.embedding_layer)
hid_bias_grad = np.sum(hid_deriv, axis=0)

"checking.print_gradients()" Output:
loss_derivative[2, 5] 0.0013789153741
loss_derivative[2, 121] -0.999459885968
loss_derivative[5, 33] 0.000391942483563
loss_derivative[5, 31] -0.708749715825

param_gradient.word_embedding_weights[27, 2] -0.298510438589
param_gradient.word_embedding_weights[43, 3] -1.13004162742
param_gradient.word_embedding_weights[22, 4] -0.211118814492
param_gradient.word_embedding_weights[2, 5] 0.0

param_gradient.embed_to_hid_weights[10, 2] -0.0128399532941
param_gradient.embed_to_hid_weights[15, 3] 0.0937808780803
param_gradient.embed_to_hid_weights[30, 9] -0.16837240452
param_gradient.embed_to_hid_weights[35, 21] 0.0619595914046

param_gradient.hid_bias[10] -0.125907091215
param_gradient.hid_bias[20] -0.389817847348

param_gradient.output_bias[0] -2.23233392034
param_gradient.output_bias[1] 0.0333102255428
param_gradient.output_bias[2] -0.743090094025
param_gradient.output_bias[3] 0.162372657748

Part 3
1)
Using the words "dr. john said", which had no occurrences in the raw texts, I got sentenses like 

2)


3)
The words 'new' and 'york' are not close together in the learned representation (they have a distance of about 4.37). This is because the word 'new' is more likely to be used as an adjective preceding other nouns than it is likely to be used as a proper noun in the name 'New York'. 

4)
The words 'government' and 'university' has closer together in the learned representation (approximately 1.28, rather than approximately 1.80 in 'government' and 'political'). I believe that this is because 
